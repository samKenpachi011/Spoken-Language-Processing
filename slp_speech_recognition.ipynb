{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechRecognition \n",
    "## Using the SpeechRecognition Library\n",
    "### we'll look at  \n",
    "- ### why we use SpeechRecognition\n",
    "- ### how to use google SR api to transcribe speech to text\n",
    "\n",
    "### The main goal is to trascribe audio to text and there many libraries out there some are still in development.There is Wav2letter++ by Facebook,CMU Sphinx and SpeechRecognition by Google library.\n",
    "\n",
    "\n",
    "- Getting started first install SpeechRecognition\n",
    "     pip install SpeechRecognition in a CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To save typing speech_recognition every time, we'll import it as sr.\n",
    "We'll also setup an instance of the Recognizer class to use later.\n",
    "The energy_threshold is a number between 0 and 4000 for how much the \n",
    "Recognizer class should listen to an audio file.\n",
    "energy_threshold will dynamically adjust whilst the recognizer\n",
    " class listens to audio. Create an instance of the Recognizer class\"\"\"\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "# Set the energy threshold\n",
    "recognizer.energy_threshold = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "``audio_data`` must be audio data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c27a8e32c41d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m text = recognizer.recognize_google(\n\u001b[0;32m      6\u001b[0m   \u001b[0maudio_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_audio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   language='en-US')\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0mRaises\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mspeech_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnknownValueError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspeech\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0munintelligible\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mRaises\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mspeech_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspeech\u001b[0m \u001b[0mrecognition\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mno\u001b[0m \u001b[0minternet\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m--> 822\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudioData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"``audio_data`` must be audio data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"``key`` must be ``None`` or a string\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"``language`` must be a string\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ``audio_data`` must be audio data"
     ]
    }
   ],
   "source": [
    "#created an instance of the Recognizer class we'll use the recognize_google() method on it to access the Google web\n",
    "#speech API and turn spoken language into text by passing it the audio and defining the language of the text\n",
    "#we'll use the  good morning audio as test_audio\n",
    "test_audio = sr.AudioFile('sounds/r3_goodMorning.wav')\n",
    "text = recognizer.recognize_google(\n",
    "  audio_data=test_audio, \n",
    "  language='en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning\n"
     ]
    }
   ],
   "source": [
    "#The above process did not run and suggests that the audio file must be an audio data\n",
    "#Let change the audio file into audio data and run the process.\n",
    "# Convert audio to AudioFile\n",
    "test_audio= sr.AudioFile('sounds/r3_goodMorning.wav')\n",
    "# Convert AudioFile to AudioData\n",
    "with test_audio as source:  \n",
    " audio_data = recognizer.record(source)\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(audio_data ,             \n",
    "                     language=\"en-US\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Speech recognition can be resource intensive, so in practice,\n",
    "you'll want to explore your audio files to make you're not wasting any\n",
    "compute power trying to transcribe static or silence.\n",
    "\"\"\"\n",
    "#Sometimes you may not want the entire audio file you're working with.\n",
    "#The duration and offset parameters of the record() method can help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello can I order pizza please\n"
     ]
    }
   ],
   "source": [
    "#Lets start with the static audio\n",
    "# Convert audio to AudioFile\n",
    "static_at_start  = sr.AudioFile('sounds/r6_static_noise_at_start.wav')\n",
    "# Convert AudioFile to AudioData\n",
    "with static_at_start as source: \n",
    " static_at_start_audio = recognizer.record(source,                   \n",
    "                           duration=None,                          \n",
    "                    offset=3.0)\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(static_at_start_audio,    \n",
    "                              language=\"en-US\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this audio file has 30 seconds of nothing at the end of it\n"
     ]
    }
   ],
   "source": [
    "# Convert audio to AudioFile\n",
    "nothing_at_end = sr.AudioFile('sounds/r7_nothing_at_end.wav')\n",
    "# Convert AudioFile to AudioData\n",
    "with nothing_at_end as source:\n",
    "   nothing_at_end_audio = recognizer.record(source,              \n",
    "                              duration=10.0,                        \n",
    "                     offset=None)\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(nothing_at_end_audio,                  \n",
    "                 language=\"en-US\")\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
